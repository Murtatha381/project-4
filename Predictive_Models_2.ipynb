{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "581d65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd43b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'heart_disease_health_indicators_BRFSS2015.csv'\n",
    "output_file = 'output.csv'\n",
    "df = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a0dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5df7647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                   0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1                   0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2                   0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3                   0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4                   0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "5                   0.0     1.0       1.0        1.0  25.0     1.0     0.0   \n",
       "6                   0.0     1.0       0.0        1.0  30.0     1.0     0.0   \n",
       "7                   0.0     1.0       1.0        1.0  25.0     1.0     0.0   \n",
       "8                   1.0     1.0       1.0        1.0  30.0     1.0     0.0   \n",
       "9                   0.0     0.0       0.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
       "0       0.0           0.0     0.0  ...            1.0          0.0      5.0   \n",
       "1       0.0           1.0     0.0  ...            0.0          1.0      3.0   \n",
       "2       0.0           0.0     1.0  ...            1.0          1.0      5.0   \n",
       "3       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
       "4       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
       "5       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
       "6       0.0           0.0     0.0  ...            1.0          0.0      3.0   \n",
       "7       0.0           1.0     0.0  ...            1.0          0.0      3.0   \n",
       "8       2.0           0.0     1.0  ...            1.0          0.0      5.0   \n",
       "9       0.0           0.0     0.0  ...            1.0          0.0      2.0   \n",
       "\n",
       "   MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \n",
       "0      18.0      15.0       1.0  0.0   9.0        4.0     3.0  \n",
       "1       0.0       0.0       0.0  0.0   7.0        6.0     1.0  \n",
       "2      30.0      30.0       1.0  0.0   9.0        4.0     8.0  \n",
       "3       0.0       0.0       0.0  0.0  11.0        3.0     6.0  \n",
       "4       3.0       0.0       0.0  0.0  11.0        5.0     4.0  \n",
       "5       0.0       2.0       0.0  1.0  10.0        6.0     8.0  \n",
       "6       0.0      14.0       0.0  0.0   9.0        6.0     7.0  \n",
       "7       0.0       0.0       1.0  0.0  11.0        4.0     4.0  \n",
       "8      30.0      30.0       1.0  0.0   9.0        5.0     1.0  \n",
       "9       0.0       0.0       0.0  1.0   8.0        4.0     3.0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b4c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data_scaled = StandardScaler().fit_transform(df[[\"HighBP\",\"HighChol\",\"CholCheck\",\"BMI\",\"Smoker\",\"Stroke\",\"Diabetes\",\"PhysActivity\",\n",
    "                                                       \"Fruits\",\"Veggies\",\"HvyAlcoholConsump\",\"AnyHealthcare\",\"NoDocbcCost\",\"GenHlth\",\"MentHlth\",\n",
    "                                                       \"PhysHlth\",\"DiffWalk\",\"Sex\",\"Age\",\"Education\",\"Income\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0d6dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>1.757936</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>2.329121</td>\n",
       "      <td>1.998592</td>\n",
       "      <td>1.233999</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>-1.474487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>-5.078164</td>\n",
       "      <td>-0.511806</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.407954</td>\n",
       "      <td>3.298445</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>-0.337933</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>-2.440138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.057858</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>3.298445</td>\n",
       "      <td>2.329121</td>\n",
       "      <td>3.617407</td>\n",
       "      <td>2.954590</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>0.939638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.209174</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>-2.080028</td>\n",
       "      <td>-0.026012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.663122</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.024926</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>-0.051162</td>\n",
       "      <td>-0.991662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.511806</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.257180</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>1.127369</td>\n",
       "      <td>0.644317</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.939638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>0.244774</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>1.119293</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.456813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.511806</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>-0.991662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>0.244774</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>2.439387</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>2.329121</td>\n",
       "      <td>3.617407</td>\n",
       "      <td>2.954590</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>-0.051162</td>\n",
       "      <td>-2.440138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.663122</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>1.127369</td>\n",
       "      <td>-0.010516</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>-1.474487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HighBP  HighChol  CholCheck       BMI    Smoker    Stroke  Diabetes  \\\n",
       "0  1.153688  1.165254   0.196922  1.757936  1.120927 -0.205637 -0.425292   \n",
       "1 -0.866785 -0.858182  -5.078164 -0.511806  1.120927 -0.205637 -0.425292   \n",
       "2  1.153688  1.165254   0.196922 -0.057858 -0.892119 -0.205637 -0.425292   \n",
       "3  1.153688 -0.858182   0.196922 -0.209174 -0.892119 -0.205637 -0.425292   \n",
       "4  1.153688  1.165254   0.196922 -0.663122 -0.892119 -0.205637 -0.425292   \n",
       "5  1.153688  1.165254   0.196922 -0.511806  1.120927 -0.205637 -0.425292   \n",
       "6  1.153688 -0.858182   0.196922  0.244774  1.120927 -0.205637 -0.425292   \n",
       "7  1.153688  1.165254   0.196922 -0.511806  1.120927 -0.205637 -0.425292   \n",
       "8  1.153688  1.165254   0.196922  0.244774  1.120927 -0.205637  2.439387   \n",
       "9 -0.866785 -0.858182   0.196922 -0.663122 -0.892119 -0.205637 -0.425292   \n",
       "\n",
       "   PhysActivity    Fruits   Veggies  ...  AnyHealthcare  NoDocbcCost  \\\n",
       "0     -1.762814 -1.316872  0.482087  ...       0.226863    -0.303173   \n",
       "1      0.567275 -1.316872 -2.074316  ...      -4.407954     3.298445   \n",
       "2     -1.762814  0.759375 -2.074316  ...       0.226863     3.298445   \n",
       "3      0.567275  0.759375  0.482087  ...       0.226863    -0.303173   \n",
       "4      0.567275  0.759375  0.482087  ...       0.226863    -0.303173   \n",
       "5      0.567275  0.759375  0.482087  ...       0.226863    -0.303173   \n",
       "6     -1.762814 -1.316872 -2.074316  ...       0.226863    -0.303173   \n",
       "7      0.567275 -1.316872  0.482087  ...       0.226863    -0.303173   \n",
       "8     -1.762814  0.759375  0.482087  ...       0.226863    -0.303173   \n",
       "9     -1.762814 -1.316872  0.482087  ...       0.226863    -0.303173   \n",
       "\n",
       "    GenHlth  MentHlth  PhysHlth  DiffWalk       Sex       Age  Education  \\\n",
       "0  2.329121  1.998592  1.233999  2.223615 -0.887021  0.316900  -1.065595   \n",
       "1  0.457294 -0.429630 -0.486592 -0.449718 -0.887021 -0.337933   0.963272   \n",
       "2  2.329121  3.617407  2.954590  2.223615 -0.887021  0.316900  -1.065595   \n",
       "3 -0.478619 -0.429630 -0.486592 -0.449718 -0.887021  0.971733  -2.080028   \n",
       "4 -0.478619 -0.024926 -0.486592 -0.449718 -0.887021  0.971733  -0.051162   \n",
       "5 -0.478619 -0.429630 -0.257180 -0.449718  1.127369  0.644317   0.963272   \n",
       "6  0.457294 -0.429630  1.119293 -0.449718 -0.887021  0.316900   0.963272   \n",
       "7  0.457294 -0.429630 -0.486592  2.223615 -0.887021  0.971733  -1.065595   \n",
       "8  2.329121  3.617407  2.954590  2.223615 -0.887021  0.316900  -0.051162   \n",
       "9 -0.478619 -0.429630 -0.486592 -0.449718  1.127369 -0.010516  -1.065595   \n",
       "\n",
       "     Income  \n",
       "0 -1.474487  \n",
       "1 -2.440138  \n",
       "2  0.939638  \n",
       "3 -0.026012  \n",
       "4 -0.991662  \n",
       "5  0.939638  \n",
       "6  0.456813  \n",
       "7 -0.991662  \n",
       "8 -2.440138  \n",
       "9 -1.474487  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heart_scaled = pd.DataFrame(heart_data_scaled,columns=[\"HighBP\",\"HighChol\",\"CholCheck\",\"BMI\",\"Smoker\",\"Stroke\",\"Diabetes\",\"PhysActivity\",\n",
    "                                                       \"Fruits\",\"Veggies\",\"HvyAlcoholConsump\",\"AnyHealthcare\",\"NoDocbcCost\",\"GenHlth\",\"MentHlth\",\n",
    "                                                       \"PhysHlth\",\"DiffWalk\",\"Sex\",\"Age\",\"Education\",\"Income\"])\n",
    "df_heart_scaled.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27465fc4",
   "metadata": {},
   "source": [
    "## Unsupervised (most accurate results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d8e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97017345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df_heart_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d82e9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_clusters = model.predict(df_heart_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59133c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>HeartRisk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>1.757936</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>2.329121</td>\n",
       "      <td>1.998592</td>\n",
       "      <td>1.233999</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>-1.474487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>-5.078164</td>\n",
       "      <td>-0.511806</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>3.298445</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>-0.337933</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>-2.440138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.057858</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>3.298445</td>\n",
       "      <td>2.329121</td>\n",
       "      <td>3.617407</td>\n",
       "      <td>2.954590</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>0.939638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.209174</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>-2.080028</td>\n",
       "      <td>-0.026012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.663122</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.024926</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>-0.051162</td>\n",
       "      <td>-0.991662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.511806</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.257180</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>1.127369</td>\n",
       "      <td>0.644317</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.939638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>0.244774</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>1.119293</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.456813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.511806</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>-0.991662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>0.244774</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>2.439387</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>2.329121</td>\n",
       "      <td>3.617407</td>\n",
       "      <td>2.954590</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>-0.051162</td>\n",
       "      <td>-2.440138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.663122</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>1.127369</td>\n",
       "      <td>-0.010516</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>-1.474487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.511806</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>2.439387</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>1.127369</td>\n",
       "      <td>1.626566</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.939638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>0.850039</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>2.954590</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.644317</td>\n",
       "      <td>-0.051162</td>\n",
       "      <td>-2.440138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.360490</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>1.233999</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>-0.337933</td>\n",
       "      <td>-0.051162</td>\n",
       "      <td>0.456813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.057858</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>2.439387</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>1.393207</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>-0.026012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>0.698723</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>4.862949</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>3.298445</td>\n",
       "      <td>1.393207</td>\n",
       "      <td>3.617407</td>\n",
       "      <td>2.725178</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>-1.320182</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>-1.957312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>0.698723</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>0.244876</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>-0.665349</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.939638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-1.117071</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.644317</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>-1.474487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.814438</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>2.439387</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>1.127369</td>\n",
       "      <td>-0.337933</td>\n",
       "      <td>-0.051162</td>\n",
       "      <td>-0.026012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>-5.078164</td>\n",
       "      <td>-0.814438</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>1.593889</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>-1.975015</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.456813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.057858</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>0.919382</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>1.127369</td>\n",
       "      <td>-1.320182</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.939638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HighBP  HighChol  CholCheck       BMI    Smoker    Stroke  Diabetes  \\\n",
       "0   1.153688  1.165254   0.196922  1.757936  1.120927 -0.205637 -0.425292   \n",
       "1  -0.866785 -0.858182  -5.078164 -0.511806  1.120927 -0.205637 -0.425292   \n",
       "2   1.153688  1.165254   0.196922 -0.057858 -0.892119 -0.205637 -0.425292   \n",
       "3   1.153688 -0.858182   0.196922 -0.209174 -0.892119 -0.205637 -0.425292   \n",
       "4   1.153688  1.165254   0.196922 -0.663122 -0.892119 -0.205637 -0.425292   \n",
       "5   1.153688  1.165254   0.196922 -0.511806  1.120927 -0.205637 -0.425292   \n",
       "6   1.153688 -0.858182   0.196922  0.244774  1.120927 -0.205637 -0.425292   \n",
       "7   1.153688  1.165254   0.196922 -0.511806  1.120927 -0.205637 -0.425292   \n",
       "8   1.153688  1.165254   0.196922  0.244774  1.120927 -0.205637  2.439387   \n",
       "9  -0.866785 -0.858182   0.196922 -0.663122 -0.892119 -0.205637 -0.425292   \n",
       "10 -0.866785 -0.858182   0.196922 -0.511806  1.120927 -0.205637  2.439387   \n",
       "11  1.153688  1.165254   0.196922  0.850039  1.120927 -0.205637 -0.425292   \n",
       "12 -0.866785 -0.858182   0.196922 -0.360490  1.120927 -0.205637 -0.425292   \n",
       "13  1.153688  1.165254   0.196922 -0.057858 -0.892119 -0.205637  2.439387   \n",
       "14 -0.866785  1.165254   0.196922  0.698723  1.120927  4.862949 -0.425292   \n",
       "15  1.153688 -0.858182   0.196922  0.698723 -0.892119 -0.205637 -0.425292   \n",
       "16  1.153688  1.165254   0.196922 -1.117071 -0.892119 -0.205637 -0.425292   \n",
       "17 -0.866785 -0.858182   0.196922 -0.814438  1.120927 -0.205637  2.439387   \n",
       "18 -0.866785 -0.858182  -5.078164 -0.814438 -0.892119 -0.205637 -0.425292   \n",
       "19 -0.866785  1.165254   0.196922 -0.057858 -0.892119 -0.205637 -0.425292   \n",
       "\n",
       "    PhysActivity    Fruits   Veggies  ...  NoDocbcCost   GenHlth  MentHlth  \\\n",
       "0      -1.762814 -1.316872  0.482087  ...    -0.303173  2.329121  1.998592   \n",
       "1       0.567275 -1.316872 -2.074316  ...     3.298445  0.457294 -0.429630   \n",
       "2      -1.762814  0.759375 -2.074316  ...     3.298445  2.329121  3.617407   \n",
       "3       0.567275  0.759375  0.482087  ...    -0.303173 -0.478619 -0.429630   \n",
       "4       0.567275  0.759375  0.482087  ...    -0.303173 -0.478619 -0.024926   \n",
       "5       0.567275  0.759375  0.482087  ...    -0.303173 -0.478619 -0.429630   \n",
       "6      -1.762814 -1.316872 -2.074316  ...    -0.303173  0.457294 -0.429630   \n",
       "7       0.567275 -1.316872  0.482087  ...    -0.303173  0.457294 -0.429630   \n",
       "8      -1.762814  0.759375  0.482087  ...    -0.303173  2.329121  3.617407   \n",
       "9      -1.762814 -1.316872  0.482087  ...    -0.303173 -0.478619 -0.429630   \n",
       "10      0.567275  0.759375  0.482087  ...    -0.303173  0.457294 -0.429630   \n",
       "11     -1.762814  0.759375  0.482087  ...    -0.303173  0.457294 -0.429630   \n",
       "12     -1.762814 -1.316872  0.482087  ...    -0.303173  0.457294 -0.429630   \n",
       "13     -1.762814 -1.316872  0.482087  ...    -0.303173  1.393207 -0.429630   \n",
       "14      0.567275 -1.316872  0.482087  ...     3.298445  1.393207  3.617407   \n",
       "15      0.567275 -1.316872 -2.074316  ...    -0.303173 -0.478619  0.244876   \n",
       "16      0.567275  0.759375  0.482087  ...    -0.303173  0.457294 -0.429630   \n",
       "17      0.567275 -1.316872 -2.074316  ...    -0.303173 -0.478619 -0.429630   \n",
       "18     -1.762814 -1.316872  0.482087  ...    -0.303173 -0.478619  1.593889   \n",
       "19     -1.762814 -1.316872 -2.074316  ...    -0.303173 -0.478619  0.919382   \n",
       "\n",
       "    PhysHlth  DiffWalk       Sex       Age  Education    Income  HeartRisk  \n",
       "0   1.233999  2.223615 -0.887021  0.316900  -1.065595 -1.474487          0  \n",
       "1  -0.486592 -0.449718 -0.887021 -0.337933   0.963272 -2.440138          1  \n",
       "2   2.954590  2.223615 -0.887021  0.316900  -1.065595  0.939638          0  \n",
       "3  -0.486592 -0.449718 -0.887021  0.971733  -2.080028 -0.026012          1  \n",
       "4  -0.486592 -0.449718 -0.887021  0.971733  -0.051162 -0.991662          1  \n",
       "5  -0.257180 -0.449718  1.127369  0.644317   0.963272  0.939638          1  \n",
       "6   1.119293 -0.449718 -0.887021  0.316900   0.963272  0.456813          0  \n",
       "7  -0.486592  2.223615 -0.887021  0.971733  -1.065595 -0.991662          0  \n",
       "8   2.954590  2.223615 -0.887021  0.316900  -0.051162 -2.440138          0  \n",
       "9  -0.486592 -0.449718  1.127369 -0.010516  -1.065595 -1.474487          1  \n",
       "10 -0.486592 -0.449718  1.127369  1.626566   0.963272  0.939638          1  \n",
       "11  2.954590  2.223615 -0.887021  0.644317  -0.051162 -2.440138          0  \n",
       "12  1.233999 -0.449718 -0.887021 -0.337933  -0.051162  0.456813          1  \n",
       "13 -0.486592  2.223615 -0.887021  0.971733  -1.065595 -0.026012          0  \n",
       "14  2.725178 -0.449718 -0.887021 -1.320182   0.963272 -1.957312          0  \n",
       "15 -0.486592 -0.449718 -0.887021 -0.665349   0.963272  0.939638          1  \n",
       "16 -0.486592 -0.449718 -0.887021  0.644317  -1.065595 -1.474487          1  \n",
       "17 -0.486592 -0.449718  1.127369 -0.337933  -0.051162 -0.026012          1  \n",
       "18 -0.486592 -0.449718 -0.887021 -1.975015   0.963272  0.456813          1  \n",
       "19 -0.486592 -0.449718  1.127369 -1.320182   0.963272  0.939638          1  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heart_scaled_predictions = df_heart_scaled.copy()\n",
    "df_heart_scaled_predictions[\"HeartRisk\"] = heart_clusters\n",
    "\n",
    "df_heart_scaled_predictions.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d82565",
   "metadata": {},
   "source": [
    "## Supervised -- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46032252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>1.757936</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>2.329121</td>\n",
       "      <td>1.998592</td>\n",
       "      <td>1.233999</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>-1.474487</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.866785</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>-5.078164</td>\n",
       "      <td>-0.511806</td>\n",
       "      <td>1.120927</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>-1.316872</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>3.298445</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>-0.337933</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>-2.440138</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.057858</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>-1.762814</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>-2.074316</td>\n",
       "      <td>...</td>\n",
       "      <td>3.298445</td>\n",
       "      <td>2.329121</td>\n",
       "      <td>3.617407</td>\n",
       "      <td>2.954590</td>\n",
       "      <td>2.223615</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>-1.065595</td>\n",
       "      <td>0.939638</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>-0.858182</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.209174</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.429630</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>-2.080028</td>\n",
       "      <td>-0.026012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.153688</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>-0.663122</td>\n",
       "      <td>-0.892119</td>\n",
       "      <td>-0.205637</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.567275</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303173</td>\n",
       "      <td>-0.478619</td>\n",
       "      <td>-0.024926</td>\n",
       "      <td>-0.486592</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>-0.051162</td>\n",
       "      <td>-0.991662</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HighBP  HighChol  CholCheck       BMI    Smoker    Stroke  Diabetes  \\\n",
       "0  1.153688  1.165254   0.196922  1.757936  1.120927 -0.205637 -0.425292   \n",
       "1 -0.866785 -0.858182  -5.078164 -0.511806  1.120927 -0.205637 -0.425292   \n",
       "2  1.153688  1.165254   0.196922 -0.057858 -0.892119 -0.205637 -0.425292   \n",
       "3  1.153688 -0.858182   0.196922 -0.209174 -0.892119 -0.205637 -0.425292   \n",
       "4  1.153688  1.165254   0.196922 -0.663122 -0.892119 -0.205637 -0.425292   \n",
       "\n",
       "   PhysActivity    Fruits   Veggies  ...  NoDocbcCost   GenHlth  MentHlth  \\\n",
       "0     -1.762814 -1.316872  0.482087  ...    -0.303173  2.329121  1.998592   \n",
       "1      0.567275 -1.316872 -2.074316  ...     3.298445  0.457294 -0.429630   \n",
       "2     -1.762814  0.759375 -2.074316  ...     3.298445  2.329121  3.617407   \n",
       "3      0.567275  0.759375  0.482087  ...    -0.303173 -0.478619 -0.429630   \n",
       "4      0.567275  0.759375  0.482087  ...    -0.303173 -0.478619 -0.024926   \n",
       "\n",
       "   PhysHlth  DiffWalk       Sex       Age  Education    Income  \\\n",
       "0  1.233999  2.223615 -0.887021  0.316900  -1.065595 -1.474487   \n",
       "1 -0.486592 -0.449718 -0.887021 -0.337933   0.963272 -2.440138   \n",
       "2  2.954590  2.223615 -0.887021  0.316900  -1.065595  0.939638   \n",
       "3 -0.486592 -0.449718 -0.887021  0.971733  -2.080028 -0.026012   \n",
       "4 -0.486592 -0.449718 -0.887021  0.971733  -0.051162 -0.991662   \n",
       "\n",
       "   HeartDiseaseorAttack  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heart_scaled2 = df_heart_scaled.copy()\n",
    "df_heart_scaled2[\"HeartDiseaseorAttack\"] = df[\"HeartDiseaseorAttack\"]\n",
    "df_heart_scaled2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0136ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae6be7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_heart_scaled2[\"HeartDiseaseorAttack\"]\n",
    "X = df_heart_scaled2.drop(columns=[\"HeartDiseaseorAttack\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce2249a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = LogisticRegression(random_state=9)\n",
    "lr_model = logistic_regression_model.fit(X_train, y_train)\n",
    "training_predictions = lr_model.predict(X_train)\n",
    "testing_predictions = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "655f7bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95    172413\n",
      "         1.0       0.55      0.13      0.21     17847\n",
      "\n",
      "    accuracy                           0.91    190260\n",
      "   macro avg       0.73      0.56      0.58    190260\n",
      "weighted avg       0.88      0.91      0.88    190260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_report = classification_report(y_train, training_predictions)\n",
    "print(training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b28e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95     57374\n",
      "         1.0       0.54      0.12      0.20      6046\n",
      "\n",
      "    accuracy                           0.91     63420\n",
      "   macro avg       0.73      0.56      0.58     63420\n",
      "weighted avg       0.88      0.91      0.88     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_report = classification_report(y_test, testing_predictions)\n",
    "print(testing_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f4b0f",
   "metadata": {},
   "source": [
    "## Supervised -- SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "print('Test Acc: %.3f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5372305",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030488d",
   "metadata": {},
   "source": [
    "## Supervised -- Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b41cd494",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_heart_scaled2[\"HeartDiseaseorAttack\"].values.reshape(-1, 1)\n",
    "X = df_heart_scaled2.drop(columns=[\"HeartDiseaseorAttack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56136fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=9)\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "733b87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model = model.fit(X_train_scaled, y_train)\n",
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "393bcaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.91      0.92     57374\n",
      "         1.0       0.24      0.27      0.25      6046\n",
      "\n",
      "    accuracy                           0.85     63420\n",
      "   macro avg       0.58      0.59      0.59     63420\n",
      "weighted avg       0.86      0.85      0.85     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd74072",
   "metadata": {},
   "source": [
    "## Supervised -- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "265f28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y = df_heart_scaled2[\"HeartDiseaseorAttack\"]\n",
    "X = df_heart_scaled2.drop(columns=[\"HeartDiseaseorAttack\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a022bb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=9)\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0924b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89cb9b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0822650464130001, 'BMI'),\n",
       " (0.08160813939628872, 'Sedentary Hours Per Day'),\n",
       " (0.08134381410903704, 'Income'),\n",
       " (0.08126686725662448, 'Exercise Hours Per Week'),\n",
       " (0.08033056711413102, 'Triglycerides'),\n",
       " (0.07754317158210133, 'Cholesterol'),\n",
       " (0.07299243394210482, 'Systolic'),\n",
       " (0.07158706104430276, 'Heart Rate'),\n",
       " (0.07113410077492625, 'Age'),\n",
       " (0.0670401566463874, 'Diastolic')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rf_model.feature_importances_\n",
    "# List the top 10 most important features\n",
    "importances_sorted = sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "importances_sorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872d414",
   "metadata": {},
   "source": [
    "## Supervised -- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9dd2ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4018d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     59996\n",
      "         1.0       0.19      0.34      0.25      3424\n",
      "\n",
      "    accuracy                           0.89     63420\n",
      "   macro avg       0.58      0.63      0.59     63420\n",
      "weighted avg       0.92      0.89      0.90     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8670cd",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "411ba44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "350c2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_heart_scaled2[\"HeartDiseaseorAttack\"]\n",
    "X = df_heart_scaled2.drop(columns=[\"HeartDiseaseorAttack\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37bb48d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 48)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 48)                2352      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 48)                2352      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 49        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5809 (22.69 KB)\n",
      "Trainable params: 5809 (22.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=48, activation=\"relu\", input_dim=21))\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=48, activation=\"relu\"))\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=48, activation=\"relu\"))\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95092273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5946/5946 [==============================] - 6s 970us/step - loss: 0.2406 - accuracy: 0.9078\n",
      "Epoch 2/100\n",
      "5946/5946 [==============================] - 6s 954us/step - loss: 0.2369 - accuracy: 0.9083\n",
      "Epoch 3/100\n",
      "5946/5946 [==============================] - 6s 956us/step - loss: 0.2361 - accuracy: 0.9086\n",
      "Epoch 4/100\n",
      "5946/5946 [==============================] - 6s 956us/step - loss: 0.2356 - accuracy: 0.9086\n",
      "Epoch 5/100\n",
      "5946/5946 [==============================] - 6s 955us/step - loss: 0.2350 - accuracy: 0.9086\n",
      "Epoch 6/100\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.2347 - accuracy: 0.9090\n",
      "Epoch 7/100\n",
      "5946/5946 [==============================] - 6s 957us/step - loss: 0.2342 - accuracy: 0.9091\n",
      "Epoch 8/100\n",
      "5946/5946 [==============================] - 6s 961us/step - loss: 0.2339 - accuracy: 0.9092\n",
      "Epoch 9/100\n",
      "5946/5946 [==============================] - 6s 959us/step - loss: 0.2336 - accuracy: 0.9093\n",
      "Epoch 10/100\n",
      "5946/5946 [==============================] - 6s 942us/step - loss: 0.2334 - accuracy: 0.9092\n",
      "Epoch 11/100\n",
      "5946/5946 [==============================] - 6s 957us/step - loss: 0.2330 - accuracy: 0.9092\n",
      "Epoch 12/100\n",
      "5946/5946 [==============================] - 6s 942us/step - loss: 0.2329 - accuracy: 0.9095\n",
      "Epoch 13/100\n",
      "5946/5946 [==============================] - 6s 960us/step - loss: 0.2325 - accuracy: 0.9097\n",
      "Epoch 14/100\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: 0.2323 - accuracy: 0.9095\n",
      "Epoch 15/100\n",
      "5946/5946 [==============================] - 6s 949us/step - loss: 0.2319 - accuracy: 0.9099\n",
      "Epoch 16/100\n",
      "5946/5946 [==============================] - 6s 957us/step - loss: 0.2318 - accuracy: 0.9098\n",
      "Epoch 17/100\n",
      "5946/5946 [==============================] - 6s 956us/step - loss: 0.2313 - accuracy: 0.9097\n",
      "Epoch 18/100\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: 0.2311 - accuracy: 0.9101\n",
      "Epoch 19/100\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.2306 - accuracy: 0.9103\n",
      "Epoch 20/100\n",
      "5946/5946 [==============================] - 6s 956us/step - loss: 0.2304 - accuracy: 0.9103\n",
      "Epoch 21/100\n",
      "5946/5946 [==============================] - 6s 949us/step - loss: 0.2300 - accuracy: 0.9104\n",
      "Epoch 22/100\n",
      "5946/5946 [==============================] - 6s 945us/step - loss: 0.2296 - accuracy: 0.9103\n",
      "Epoch 23/100\n",
      "5946/5946 [==============================] - 6s 946us/step - loss: 0.2294 - accuracy: 0.9108\n",
      "Epoch 24/100\n",
      "5946/5946 [==============================] - 6s 945us/step - loss: 0.2290 - accuracy: 0.9108\n",
      "Epoch 25/100\n",
      "5946/5946 [==============================] - 6s 945us/step - loss: 0.2285 - accuracy: 0.9110\n",
      "Epoch 26/100\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.2284 - accuracy: 0.9109\n",
      "Epoch 27/100\n",
      "5946/5946 [==============================] - 6s 942us/step - loss: 0.2281 - accuracy: 0.9110\n",
      "Epoch 28/100\n",
      "5946/5946 [==============================] - 6s 939us/step - loss: 0.2278 - accuracy: 0.9113\n",
      "Epoch 29/100\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: 0.2274 - accuracy: 0.9113\n",
      "Epoch 30/100\n",
      "5946/5946 [==============================] - 6s 959us/step - loss: 0.2270 - accuracy: 0.9113\n",
      "Epoch 31/100\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.2268 - accuracy: 0.9114\n",
      "Epoch 32/100\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.2266 - accuracy: 0.9114\n",
      "Epoch 33/100\n",
      "5946/5946 [==============================] - 6s 949us/step - loss: 0.2265 - accuracy: 0.9115\n",
      "Epoch 34/100\n",
      "5946/5946 [==============================] - 6s 944us/step - loss: 0.2262 - accuracy: 0.9116\n",
      "Epoch 35/100\n",
      "5946/5946 [==============================] - 6s 966us/step - loss: 0.2260 - accuracy: 0.9116\n",
      "Epoch 36/100\n",
      "5946/5946 [==============================] - 6s 950us/step - loss: 0.2256 - accuracy: 0.9119\n",
      "Epoch 37/100\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.2255 - accuracy: 0.9118\n",
      "Epoch 38/100\n",
      "5946/5946 [==============================] - 6s 957us/step - loss: 0.2254 - accuracy: 0.9118\n",
      "Epoch 39/100\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: 0.2250 - accuracy: 0.9118\n",
      "Epoch 40/100\n",
      "5946/5946 [==============================] - 6s 955us/step - loss: 0.2250 - accuracy: 0.9122\n",
      "Epoch 41/100\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.2246 - accuracy: 0.9120\n",
      "Epoch 42/100\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.2243 - accuracy: 0.9123\n",
      "Epoch 43/100\n",
      "5946/5946 [==============================] - 6s 951us/step - loss: 0.2242 - accuracy: 0.9124\n",
      "Epoch 44/100\n",
      "5946/5946 [==============================] - 6s 939us/step - loss: 0.2240 - accuracy: 0.9124\n",
      "Epoch 45/100\n",
      "5946/5946 [==============================] - 6s 950us/step - loss: 0.2238 - accuracy: 0.9124\n",
      "Epoch 46/100\n",
      "5946/5946 [==============================] - 6s 964us/step - loss: 0.2235 - accuracy: 0.9125\n",
      "Epoch 47/100\n",
      "5946/5946 [==============================] - 6s 949us/step - loss: 0.2233 - accuracy: 0.9129\n",
      "Epoch 48/100\n",
      "5946/5946 [==============================] - 6s 951us/step - loss: 0.2231 - accuracy: 0.9130\n",
      "Epoch 49/100\n",
      "5946/5946 [==============================] - 6s 942us/step - loss: 0.2232 - accuracy: 0.9129\n",
      "Epoch 50/100\n",
      "5946/5946 [==============================] - 6s 950us/step - loss: 0.2227 - accuracy: 0.9128\n",
      "Epoch 51/100\n",
      "5946/5946 [==============================] - 6s 964us/step - loss: 0.2229 - accuracy: 0.9127\n",
      "Epoch 52/100\n",
      "5946/5946 [==============================] - 6s 950us/step - loss: 0.2226 - accuracy: 0.9130\n",
      "Epoch 53/100\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: 0.2224 - accuracy: 0.9129\n",
      "Epoch 54/100\n",
      "5946/5946 [==============================] - 6s 956us/step - loss: 0.2223 - accuracy: 0.9129\n",
      "Epoch 55/100\n",
      "5946/5946 [==============================] - 6s 939us/step - loss: 0.2222 - accuracy: 0.9130\n",
      "Epoch 56/100\n",
      "5946/5946 [==============================] - 6s 957us/step - loss: 0.2218 - accuracy: 0.9131\n",
      "Epoch 57/100\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.2221 - accuracy: 0.9132\n",
      "Epoch 58/100\n",
      "5946/5946 [==============================] - 6s 950us/step - loss: 0.2216 - accuracy: 0.9131\n",
      "Epoch 59/100\n",
      "5946/5946 [==============================] - 6s 944us/step - loss: 0.2214 - accuracy: 0.9135\n",
      "Epoch 60/100\n",
      "5946/5946 [==============================] - 6s 954us/step - loss: 0.2212 - accuracy: 0.9135\n",
      "Epoch 61/100\n",
      "5946/5946 [==============================] - 6s 951us/step - loss: 0.2214 - accuracy: 0.9135\n",
      "Epoch 62/100\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: 0.2211 - accuracy: 0.9136\n",
      "Epoch 63/100\n",
      "5946/5946 [==============================] - 6s 990us/step - loss: 0.2211 - accuracy: 0.9134\n",
      "Epoch 64/100\n",
      "5946/5946 [==============================] - 6s 937us/step - loss: 0.2207 - accuracy: 0.9137\n",
      "Epoch 65/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2208 - accuracy: 0.9138\n",
      "Epoch 66/100\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.2205 - accuracy: 0.9135\n",
      "Epoch 67/100\n",
      "5946/5946 [==============================] - 6s 992us/step - loss: 0.2204 - accuracy: 0.9136\n",
      "Epoch 68/100\n",
      "5946/5946 [==============================] - 6s 969us/step - loss: 0.2204 - accuracy: 0.9138\n",
      "Epoch 69/100\n",
      "5946/5946 [==============================] - 6s 999us/step - loss: 0.2203 - accuracy: 0.9137\n",
      "Epoch 70/100\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.2199 - accuracy: 0.9137\n",
      "Epoch 71/100\n",
      "5946/5946 [==============================] - 6s 979us/step - loss: 0.2200 - accuracy: 0.9138\n",
      "Epoch 72/100\n",
      "5946/5946 [==============================] - 6s 978us/step - loss: 0.2198 - accuracy: 0.9139\n",
      "Epoch 73/100\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.2198 - accuracy: 0.9137\n",
      "Epoch 74/100\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.2197 - accuracy: 0.9143\n",
      "Epoch 75/100\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.2194 - accuracy: 0.9140\n",
      "Epoch 76/100\n",
      "5946/5946 [==============================] - 6s 971us/step - loss: 0.2195 - accuracy: 0.9140\n",
      "Epoch 77/100\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.2193 - accuracy: 0.9141\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5946/5946 [==============================] - 9s 1ms/step - loss: 0.2193 - accuracy: 0.9142\n",
      "Epoch 79/100\n",
      "5946/5946 [==============================] - 9s 1ms/step - loss: 0.2191 - accuracy: 0.9143\n",
      "Epoch 80/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2191 - accuracy: 0.9144\n",
      "Epoch 81/100\n",
      "5946/5946 [==============================] - 8s 1ms/step - loss: 0.2188 - accuracy: 0.9142\n",
      "Epoch 82/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2189 - accuracy: 0.9142\n",
      "Epoch 83/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2188 - accuracy: 0.9144\n",
      "Epoch 84/100\n",
      "5946/5946 [==============================] - 8s 1ms/step - loss: 0.2185 - accuracy: 0.9144\n",
      "Epoch 85/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2184 - accuracy: 0.9145\n",
      "Epoch 86/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2188 - accuracy: 0.9145\n",
      "Epoch 87/100\n",
      "5946/5946 [==============================] - 8s 1ms/step - loss: 0.2183 - accuracy: 0.9146\n",
      "Epoch 88/100\n",
      "5946/5946 [==============================] - 8s 1ms/step - loss: 0.2182 - accuracy: 0.9147\n",
      "Epoch 89/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2181 - accuracy: 0.9141\n",
      "Epoch 90/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2181 - accuracy: 0.9146\n",
      "Epoch 91/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2177 - accuracy: 0.9148\n",
      "Epoch 92/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2176 - accuracy: 0.9150\n",
      "Epoch 93/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2178 - accuracy: 0.9148\n",
      "Epoch 94/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2174 - accuracy: 0.9151\n",
      "Epoch 95/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2175 - accuracy: 0.9150\n",
      "Epoch 96/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2177 - accuracy: 0.9148\n",
      "Epoch 97/100\n",
      "5946/5946 [==============================] - 7s 1ms/step - loss: 0.2172 - accuracy: 0.9149\n",
      "Epoch 98/100\n",
      "5946/5946 [==============================] - 8s 1ms/step - loss: 0.2172 - accuracy: 0.9151\n",
      "Epoch 99/100\n",
      "5946/5946 [==============================] - 9s 2ms/step - loss: 0.2174 - accuracy: 0.9151\n",
      "Epoch 100/100\n",
      "5946/5946 [==============================] - 10s 2ms/step - loss: 0.2174 - accuracy: 0.9154\n"
     ]
    }
   ],
   "source": [
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57edd729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982/1982 - 1s - loss: 0.2753 - accuracy: 0.9020 - 1s/epoch - 709us/step\n",
      "Loss: 0.2753150463104248, Accuracy: 0.9020183086395264\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ec850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
